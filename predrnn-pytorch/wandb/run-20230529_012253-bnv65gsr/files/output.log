/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1979_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1979_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1980_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1980_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1981_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1981_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1982_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1982_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1983_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1983_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1984_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1984_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1985_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1985_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1986_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1986_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1987_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1987_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1988_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1988_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1989_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1989_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1990_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1990_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1991_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1991_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1992_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1992_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1993_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1993_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1994_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1994_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1995_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1995_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1996_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1996_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1997_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1997_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1998_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1998_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1999_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1999_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2000_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2001_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2002_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2003_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2004_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2005_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2006_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2007_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2008_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2009_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2010_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2011_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2012_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2013_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2014_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2015_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2016_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2017_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2018_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2019_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2020_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2020_3_24hr_shift3.npz
train_data_files nums: 84
mnist test iterator, Loading data from /scratch/09012/haoli1/ERA5/val_dataset_6hrs/era5_train_2022_3_24hr.npz
NaN value num: 0
mnist train iterator, Loading data from /scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2016_3_24hr.npz
NaN value num: 0
load model: /work/09012/haoli1/ls6/PredRNN_checkpoints/WV_1_PC_1_EH_0_PS_40_6hrs/model_WV_1_PC_0_EH_0_PS_40_6hrs.ckpt
2023-05-29 01:24:19 testing...
The modified gen p mean: 0.4474286437034607, gen p mean: 0.4492891728878021, mean p set: 0.448
loss_pred:0.03331351652741432, decouple_loss:0.0016577725764364004
The modified gen p mean: 0.44743481278419495, gen p mean: 0.44922295212745667, mean p set: 0.448
loss_pred:0.03181175887584686, decouple_loss:0.001578469411469996
The modified gen p mean: 0.4474334120750427, gen p mean: 0.4476969242095947, mean p set: 0.448
loss_pred:0.03220827504992485, decouple_loss:0.001466704299673438
/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
WV_1_PC_1_EH_0_PS_40_6hrs, loss: 0.03252290189266205, avg_mse: 0.04372323676943779
Loaded model test mse: 0.04372299835085869
Iteration: 1, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44743627309799194, gen p mean: 0.44848135113716125, mean p set: 0.448
The modified gen p mean: 0.44742265343666077, gen p mean: 0.44385141134262085, mean p set: 0.448
loss_pred:0.03400210663676262, decouple_loss:0.0016234770882874727
loss_pred:0.03515822812914848, decouple_loss:0.0014964262954890728
The modified gen p mean: 0.4474351406097412, gen p mean: 0.44927525520324707, mean p set: 0.448
loss_pred:0.0349489226937294, decouple_loss:0.0017384596867486835
Iteration: 2, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44743695855140686, gen p mean: 0.44488850235939026, mean p set: 0.448
The modified gen p mean: 0.44743067026138306, gen p mean: 0.44750502705574036, mean p set: 0.448
loss_pred:0.03658005967736244, decouple_loss:0.0017680327873677015
loss_pred:0.03432874009013176, decouple_loss:0.0018061386654153466
The modified gen p mean: 0.4474344849586487, gen p mean: 0.4487798810005188, mean p set: 0.448
loss_pred:0.034025102853775024, decouple_loss:0.002158842282369733
Iteration: 3, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4474353790283203, gen p mean: 0.44978809356689453, mean p set: 0.448
loss_pred:0.035056859254837036, decouple_loss:0.001631372608244419
The modified gen p mean: 0.44742968678474426, gen p mean: 0.44407767057418823, mean p set: 0.448
loss_pred:0.03412937745451927, decouple_loss:0.0014089931501075625
The modified gen p mean: 0.44747060537338257, gen p mean: 0.44523483514785767, mean p set: 0.448
loss_pred:0.03207306191325188, decouple_loss:0.0014313537394627929
Iteration: 4, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4474383294582367, gen p mean: 0.44812312722206116, mean p set: 0.448
loss_pred:0.03251267224550247, decouple_loss:0.0017209525685757399
The modified gen p mean: 0.4474307596683502, gen p mean: 0.4463137686252594, mean p set: 0.448
The modified gen p mean: 0.44747620820999146, gen p mean: 0.44955533742904663, mean p set: 0.448
loss_pred:0.03397548198699951, decouple_loss:0.001439416315406561
loss_pred:0.03397655487060547, decouple_loss:0.0016407371731474996
Iteration: 5, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44744449853897095, gen p mean: 0.45113569498062134, mean p set: 0.448
loss_pred:0.034265052527189255, decouple_loss:0.0016588183352723718
The modified gen p mean: 0.44742634892463684, gen p mean: 0.4479823708534241, mean p set: 0.448
loss_pred:0.03293267637491226, decouple_loss:0.0015635518357157707
The modified gen p mean: 0.4474755525588989, gen p mean: 0.44783854484558105, mean p set: 0.448
loss_pred:0.030593587085604668, decouple_loss:0.001667903969064355
Iteration: 6, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4474373459815979, gen p mean: 0.44558632373809814, mean p set: 0.448
loss_pred:0.03274013474583626, decouple_loss:0.0017392316367477179
The modified gen p mean: 0.44742944836616516, gen p mean: 0.4458352327346802, mean p set: 0.448
loss_pred:0.03351176530122757, decouple_loss:0.0015181993367150426
The modified gen p mean: 0.4474807679653168, gen p mean: 0.4476622939109802, mean p set: 0.448
loss_pred:0.0326140858232975, decouple_loss:0.0014859819784760475
Iteration: 7, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44742485880851746, gen p mean: 0.447104275226593, mean p set: 0.448
The modified gen p mean: 0.4474373757839203, gen p mean: 0.44682231545448303, mean p set: 0.448
loss_pred:0.03437972441315651, decouple_loss:0.0014964615693315864
loss_pred:0.03531336039304733, decouple_loss:0.0014889714075252414
The modified gen p mean: 0.4474927484989166, gen p mean: 0.4467308819293976, mean p set: 0.448
loss_pred:0.033629607409238815, decouple_loss:0.0015578282764181495
Iteration: 8, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.447430819272995, gen p mean: 0.44943079352378845, mean p set: 0.448
loss_pred:0.03545690327882767, decouple_loss:0.0013511605793610215
The modified gen p mean: 0.4474200904369354, gen p mean: 0.44778281450271606, mean p set: 0.448
loss_pred:0.03287157416343689, decouple_loss:0.0013902573846280575
The modified gen p mean: 0.44747403264045715, gen p mean: 0.4498467743396759, mean p set: 0.448
loss_pred:0.035436104983091354, decouple_loss:0.0014780082274228334
Iteration: 9, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.447431743144989, gen p mean: 0.4526955485343933, mean p set: 0.448
loss_pred:0.03209293261170387, decouple_loss:0.0016930087003856897
The modified gen p mean: 0.4474395215511322, gen p mean: 0.4527052938938141, mean p set: 0.448
loss_pred:0.03571365773677826, decouple_loss:0.0016266361344605684
The modified gen p mean: 0.44747409224510193, gen p mean: 0.4526737332344055, mean p set: 0.448
loss_pred:0.033253684639930725, decouple_loss:0.0018324140692129731
Iteration: 10, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44743281602859497, gen p mean: 0.4539567828178406, mean p set: 0.448
loss_pred:0.033663298934698105, decouple_loss:0.0013925004750490189
The modified gen p mean: 0.44747763872146606, gen p mean: 0.4497469365596771, mean p set: 0.448
loss_pred:0.034090135246515274, decouple_loss:0.0014431524323299527
The modified gen p mean: 0.447435587644577, gen p mean: 0.45338642597198486, mean p set: 0.448
loss_pred:0.032938402146101, decouple_loss:0.0014711511321365833

2023-05-29 01:28:24 testing...
The modified gen p mean: 0.4474284052848816, gen p mean: 0.4563891887664795, mean p set: 0.448
loss_pred:0.03183218836784363, decouple_loss:0.0015255309408530593
The modified gen p mean: 0.447431355714798, gen p mean: 0.455060213804245, mean p set: 0.448
loss_pred:0.03221840411424637, decouple_loss:0.0015140558825805783
The modified gen p mean: 0.4474699795246124, gen p mean: 0.45666372776031494, mean p set: 0.448
loss_pred:0.03338513895869255, decouple_loss:0.0016431247349828482
Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 420, in <module>
    train_wrapper(model)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 305, in train_wrapper
    test_err = trainer.validate(model, test_input_handle, extra_var_test, args, 'val_result')
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/trainer.py", line 50, in validate
    avg_mse, loss = model.test(test_ims, real_input_flag, extra_var)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/model_factory_multiGPU.py", line 101, in test
    next_frames, loss, _, _ = self.network(frames_tensor, mask_tensor, extra_var_tensor, istrain=False)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/_utils.py", line 461, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/predrnn_mgpu.py", line 259, in forward
    next_frames = self.wv_to_img(next_frames)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/predrnn_mgpu.py", line 319, in wv_to_img
    img_tensor = self.ifm((Yl, Yh))
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/transform2d.py", line 146, in forward
    ll = lowlevel.SFB2D.apply(
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/lowlevel.py", line 679, in forward
    y = sfb1d(lo, hi, g0_row, g1_row, mode=mode, dim=3)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/lowlevel.py", line 266, in sfb1d
    y = F.conv_transpose2d(lo, g0, stride=s, padding=pad, groups=C) + \
RuntimeError: CUDA out of memory. Tried to allocate 1.91 GiB (GPU 0; 39.42 GiB total capacity; 35.42 GiB already allocated; 1.78 GiB free; 35.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF