/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1979_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1979_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1980_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1980_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1981_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1981_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1982_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1982_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1983_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1983_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1984_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1984_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1985_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1985_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1986_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1986_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1987_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1987_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1988_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1988_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1989_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1989_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1990_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1990_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1991_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1991_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1992_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1992_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1993_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1993_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1994_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1994_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1995_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1995_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1996_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1996_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1997_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1997_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1998_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1998_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1999_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1999_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2000_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2001_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2002_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2003_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2004_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2005_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2006_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2007_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2008_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2009_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2010_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2011_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2012_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2013_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2014_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2015_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2016_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2017_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2018_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2019_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2020_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2020_3_24hr_shift3.npz
train_data_files nums: 84
mnist test iterator, Loading data from /scratch/09012/haoli1/ERA5/val_dataset_6hrs/era5_train_2022_3_24hr.npz
NaN value num: 0
mnist train iterator, Loading data from /scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1983_3_24hr.npz
NaN value num: 0
load model: /work/09012/haoli1/ls6/PredRNN_checkpoints/WV_1_PC_0_EH_0_PS_40_6hrs/model_WV_1_PC_0_EH_0_PS_40_6hrs.ckpt
2023-05-29 01:30:45 testing...
The modified gen p mean: 0.44915661215782166, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.03331473097205162, decouple_loss:0.0016575435874983668
The modified gen p mean: 0.447613000869751, gen p mean: 0.0, mean p set: 0.448
The modified gen p mean: 0.44911205768585205, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.03221110254526138, decouple_loss:0.001467144931666553
loss_pred:0.031802933663129807, decouple_loss:0.0015784797724336386
/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
WV_1_PC_0_EH_0_PS_40_6hrs, loss: 0.03252130746841431, avg_mse: 0.043718308210372925
Loaded model test mse: 0.04371799901127815
Iteration: 1, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4444528818130493, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.027521664276719093, decouple_loss:0.0018409470794722438
The modified gen p mean: 0.44258934259414673, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.02849816530942917, decouple_loss:0.0015169429825618863
The modified gen p mean: 0.4458244740962982, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.02896452695131302, decouple_loss:0.001603940618224442
Iteration: 2, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44458431005477905, gen p mean: 0.0, mean p set: 0.448
The modified gen p mean: 0.44606029987335205, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.02877848595380783, decouple_loss:0.0020286415237933397
loss_pred:0.026812409982085228, decouple_loss:0.002146783983334899
The modified gen p mean: 0.44865578413009644, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.02916155755519867, decouple_loss:0.0020876924972981215
Iteration: 3, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4442382752895355, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.02818877249956131, decouple_loss:0.001843531266786158
The modified gen p mean: 0.4490959346294403, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.0289472546428442, decouple_loss:0.0016412805998697877
The modified gen p mean: 0.4453701376914978, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.026144983246922493, decouple_loss:0.0017521838890388608
Iteration: 4, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4478107988834381, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.02672894299030304, decouple_loss:0.001612147781997919
The modified gen p mean: 0.45176225900650024, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.026802318170666695, decouple_loss:0.0019251437624916434
The modified gen p mean: 0.4477287828922272, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.027272023260593414, decouple_loss:0.0015091727254912257
Iteration: 5, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44630512595176697, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.028297986835241318, decouple_loss:0.0018610272090882063
The modified gen p mean: 0.44849759340286255, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.0270097479224205, decouple_loss:0.0016450834227725863
The modified gen p mean: 0.4483560621738434, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.029207278043031693, decouple_loss:0.0015684582758694887
Iteration: 6, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4492276608943939, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.028938468545675278, decouple_loss:0.0021256934851408005
The modified gen p mean: 0.4486235976219177, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.028510861098766327, decouple_loss:0.002032450633123517
The modified gen p mean: 0.44610580801963806, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.026256348937749863, decouple_loss:0.001641597249545157
Iteration: 7, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4412122070789337, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.029277179390192032, decouple_loss:0.0016436108853667974
The modified gen p mean: 0.4429740905761719, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.02694421447813511, decouple_loss:0.0015587708912789822
The modified gen p mean: 0.4468775689601898, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.028374871239066124, decouple_loss:0.0016688834875822067
Iteration: 8, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44551631808280945, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.02644539810717106, decouple_loss:0.001952405902557075
The modified gen p mean: 0.44203412532806396, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.028770260512828827, decouple_loss:0.0018721838714554906
The modified gen p mean: 0.4412447214126587, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.027014831081032753, decouple_loss:0.0015281598316505551
Iteration: 9, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4465249478816986, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.027862438932061195, decouple_loss:0.0017146007157862186
The modified gen p mean: 0.444638729095459, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.028137527406215668, decouple_loss:0.0019911970011889935
The modified gen p mean: 0.4447839856147766, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.027548156678676605, decouple_loss:0.0016691175987944007
Iteration: 10, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4460703432559967, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.028756430372595787, decouple_loss:0.00192928034812212
The modified gen p mean: 0.4521014094352722, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.026551196351647377, decouple_loss:0.001710128621198237
The modified gen p mean: 0.44816476106643677, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.027547553181648254, decouple_loss:0.00160757708363235
2023-05-29 01:34:44 testing...
The modified gen p mean: 0.4547860622406006, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.03250056132674217, decouple_loss:0.0016642679693177342
The modified gen p mean: 0.45291823148727417, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.03267161548137665, decouple_loss:0.0015844515291973948
The modified gen p mean: 0.45452216267585754, gen p mean: 0.0, mean p set: 0.448
loss_pred:0.03369233384728432, decouple_loss:0.0017462174873799086
Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 420, in <module>
    train_wrapper(model)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 305, in train_wrapper
    test_err = trainer.validate(model, test_input_handle, extra_var_test, args, 'val_result')
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/trainer.py", line 50, in validate
    avg_mse, loss = model.test(test_ims, real_input_flag, extra_var)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/model_factory_multiGPU.py", line 101, in test
    next_frames, loss, _, _ = self.network(frames_tensor, mask_tensor, extra_var_tensor, istrain=False)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/_utils.py", line 461, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/predrnn_mgpu.py", line 259, in forward
    next_frames = self.wv_to_img(next_frames)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/predrnn_mgpu.py", line 319, in wv_to_img
    img_tensor = self.ifm((Yl, Yh))
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/transform2d.py", line 146, in forward
    ll = lowlevel.SFB2D.apply(
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/lowlevel.py", line 679, in forward
    y = sfb1d(lo, hi, g0_row, g1_row, mode=mode, dim=3)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/lowlevel.py", line 266, in sfb1d
    y = F.conv_transpose2d(lo, g0, stride=s, padding=pad, groups=C) + \
RuntimeError: CUDA out of memory. Tried to allocate 1.91 GiB (GPU 0; 39.42 GiB total capacity; 35.39 GiB already allocated; 1.74 GiB free; 35.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF