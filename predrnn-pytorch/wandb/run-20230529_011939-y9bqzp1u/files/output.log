/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1979_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1979_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1980_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1980_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1981_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1981_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1982_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1982_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1983_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1983_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1984_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1984_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1985_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1985_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1986_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1986_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1987_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1987_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1988_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1988_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1989_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1989_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1990_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1990_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1991_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1991_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1992_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1992_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1993_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1993_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1994_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1994_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1995_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1995_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1996_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1996_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1997_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1997_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1998_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1998_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1999_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1999_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2000_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2001_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2002_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2003_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2004_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2005_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2006_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2007_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2008_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2009_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2010_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2011_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2012_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2013_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2014_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2015_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2016_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2017_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2018_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2019_3_24hr_shift3.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2020_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2020_3_24hr_shift3.npz
train_data_files nums: 84
mnist test iterator, Loading data from /scratch/09012/haoli1/ERA5/val_dataset_6hrs/era5_train_2022_3_24hr.npz
NaN value num: 0
mnist train iterator, Loading data from /scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1996_3_24hr.npz
NaN value num: 0
load model: /work/09012/haoli1/ls6/PredRNN_checkpoints/WV_1_PC_1_EH_0_PS_40_6hrs/model_WV_1_PC_0_EH_0_PS_40_6hrs.ckpt
2023-05-29 01:21:01 testing...
The modified gen p mean: 0.4475250840187073, gen p mean: 0.4477463662624359, mean p set: 0.448
loss_pred:0.03220833092927933, decouple_loss:0.0014667515642940998
The modified gen p mean: 0.4475250840187073, gen p mean: 0.449272483587265, mean p set: 0.448
loss_pred:0.03181189298629761, decouple_loss:0.001578480121679604
The modified gen p mean: 0.4475250840187073, gen p mean: 0.4493384063243866, mean p set: 0.448
loss_pred:0.03331375494599342, decouple_loss:0.0016577711794525385
WV_1_PC_1_EH_0_PS_40_6hrs, loss: 0.03252304345369339, avg_mse: 0.04372335225343704
Loaded model test mse: 0.04372299835085869
Iteration: 1, ims.shape: (3, 56, 3, 720, 1440)
/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44573190808296204, mean p set: 0.448
loss_pred:0.027777159586548805, decouple_loss:0.0016119894571602345
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44960224628448486, mean p set: 0.448
loss_pred:0.02900349535048008, decouple_loss:0.0016033948631957173
The modified gen p mean: 0.4475250244140625, gen p mean: 0.4450214207172394, mean p set: 0.448
loss_pred:0.028714319691061974, decouple_loss:0.0014057372463867068
Iteration: 2, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44474244117736816, mean p set: 0.448
loss_pred:0.030707450583577156, decouple_loss:0.001894502667710185
The modified gen p mean: 0.4475250542163849, gen p mean: 0.4438464343547821, mean p set: 0.448
loss_pred:0.030460912734270096, decouple_loss:0.0020752784330397844
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44219934940338135, mean p set: 0.448
loss_pred:0.02859489433467388, decouple_loss:0.0020647149067372084
Iteration: 3, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44431427121162415, mean p set: 0.448
loss_pred:0.02863074652850628, decouple_loss:0.001547950436361134
The modified gen p mean: 0.4475250542163849, gen p mean: 0.447935551404953, mean p set: 0.448
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44368165731430054, mean p set: 0.448
loss_pred:0.028405610471963882, decouple_loss:0.0015187491662800312
loss_pred:0.027489440515637398, decouple_loss:0.0017175638349726796
Iteration: 4, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4475250542163849, gen p mean: 0.4456098973751068, mean p set: 0.448
loss_pred:0.02817070111632347, decouple_loss:0.0017376081086695194
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44264212250709534, mean p set: 0.448
loss_pred:0.02965274266898632, decouple_loss:0.00178718869574368
The modified gen p mean: 0.4475250542163849, gen p mean: 0.4419479966163635, mean p set: 0.448
loss_pred:0.02846824750304222, decouple_loss:0.0019445950165390968
Iteration: 5, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4475250244140625, gen p mean: 0.4424656927585602, mean p set: 0.448
The modified gen p mean: 0.4475250542163849, gen p mean: 0.448937326669693, mean p set: 0.448
loss_pred:0.027488211169838905, decouple_loss:0.0016706623136997223
loss_pred:0.028189893811941147, decouple_loss:0.0016050939448177814
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44705691933631897, mean p set: 0.448
loss_pred:0.028671709820628166, decouple_loss:0.0016089151613414288
Iteration: 6, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4475250244140625, gen p mean: 0.4415285289287567, mean p set: 0.448
loss_pred:0.028365759178996086, decouple_loss:0.0016347527271136642
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44626837968826294, mean p set: 0.448
The modified gen p mean: 0.4475250542163849, gen p mean: 0.4449823200702667, mean p set: 0.448
loss_pred:0.028221188113093376, decouple_loss:0.0016346032498404384
loss_pred:0.028251897543668747, decouple_loss:0.0016387113137170672
Iteration: 7, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4475250542163849, gen p mean: 0.442179411649704, mean p set: 0.448
loss_pred:0.028071584179997444, decouple_loss:0.0017111289780586958
The modified gen p mean: 0.4475250542163849, gen p mean: 0.4462985396385193, mean p set: 0.448
loss_pred:0.02825263701379299, decouple_loss:0.0016584813129156828
The modified gen p mean: 0.4475250542163849, gen p mean: 0.4423655867576599, mean p set: 0.448
loss_pred:0.02816801145672798, decouple_loss:0.001486718887463212
Iteration: 8, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.44752511382102966, gen p mean: 0.44647514820098877, mean p set: 0.448
The modified gen p mean: 0.4475250244140625, gen p mean: 0.44482919573783875, mean p set: 0.448
loss_pred:0.026882683858275414, decouple_loss:0.0018310784362256527
loss_pred:0.02733818255364895, decouple_loss:0.001656625885516405
The modified gen p mean: 0.4475250244140625, gen p mean: 0.44155094027519226, mean p set: 0.448
loss_pred:0.02927876077592373, decouple_loss:0.0017506805015727878
Iteration: 9, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4475250542163849, gen p mean: 0.4436247944831848, mean p set: 0.448
loss_pred:0.029608488082885742, decouple_loss:0.0016697505488991737
The modified gen p mean: 0.4475250542163849, gen p mean: 0.447378009557724, mean p set: 0.448
The modified gen p mean: 0.4475250244140625, gen p mean: 0.44593238830566406, mean p set: 0.448
loss_pred:0.029007038101553917, decouple_loss:0.001963256625458598
loss_pred:0.02748293988406658, decouple_loss:0.0019228382734581828
Iteration: 10, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 0.4475250244140625, gen p mean: 0.4475003182888031, mean p set: 0.448
loss_pred:0.02712000347673893, decouple_loss:0.0018210213165730238
The modified gen p mean: 0.4475250542163849, gen p mean: 0.4449934661388397, mean p set: 0.448
loss_pred:0.02772977016866207, decouple_loss:0.0015107480576261878
The modified gen p mean: 0.4475250542163849, gen p mean: 0.44403257966041565, mean p set: 0.448
loss_pred:0.027173781767487526, decouple_loss:0.0016114332247525454
2023-05-29 01:35:16 testing...
The modified gen p mean: 0.4475250840187073, gen p mean: 0.4480258524417877, mean p set: 0.448
The modified gen p mean: 0.4475250840187073, gen p mean: 0.4500160813331604, mean p set: 0.448
loss_pred:0.03297213092446327, decouple_loss:0.0016285923775285482
loss_pred:0.032474324107170105, decouple_loss:0.0017391404835507274
The modified gen p mean: 0.4475250840187073, gen p mean: 0.44988003373146057, mean p set: 0.448
loss_pred:0.03383602201938629, decouple_loss:0.0018448368646204472
Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 420, in <module>
    train_wrapper(model)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 305, in train_wrapper
    test_err = trainer.validate(model, test_input_handle, extra_var_test, args, 'val_result')
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/trainer.py", line 50, in validate
    avg_mse, loss = model.test(test_ims, real_input_flag, extra_var)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/model_factory_multiGPU.py", line 101, in test
    next_frames, loss, _, _ = self.network(frames_tensor, mask_tensor, extra_var_tensor, istrain=False)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/_utils.py", line 461, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/predrnn_mgpu.py", line 259, in forward
    next_frames = self.wv_to_img(next_frames)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/predrnn_mgpu.py", line 319, in wv_to_img
    img_tensor = self.ifm((Yl, Yh))
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/transform2d.py", line 146, in forward
    ll = lowlevel.SFB2D.apply(
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/lowlevel.py", line 679, in forward
    y = sfb1d(lo, hi, g0_row, g1_row, mode=mode, dim=3)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/pytorch_wavelets/dwt/lowlevel.py", line 266, in sfb1d
    y = F.conv_transpose2d(lo, g0, stride=s, padding=pad, groups=C) + \
RuntimeError: CUDA out of memory. Tried to allocate 1.91 GiB (GPU 0; 39.42 GiB total capacity; 35.42 GiB already allocated; 1.68 GiB free; 35.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF